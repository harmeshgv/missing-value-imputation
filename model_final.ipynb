{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   symboling         205 non-null    int64  \n",
      " 1   fueltype          205 non-null    int64  \n",
      " 2   aspiration        205 non-null    int64  \n",
      " 3   doornumber        205 non-null    int64  \n",
      " 4   carbody           205 non-null    int64  \n",
      " 5   drivewheel        205 non-null    int64  \n",
      " 6   enginelocation    205 non-null    int64  \n",
      " 7   wheelbase         205 non-null    float64\n",
      " 8   carlength         205 non-null    float64\n",
      " 9   carwidth          205 non-null    float64\n",
      " 10  carheight         205 non-null    float64\n",
      " 11  curbweight        205 non-null    int64  \n",
      " 12  enginetype        205 non-null    int64  \n",
      " 13  cylindernumber    205 non-null    int64  \n",
      " 14  enginesize        205 non-null    int64  \n",
      " 15  fuelsystem        205 non-null    int64  \n",
      " 16  boreratio         205 non-null    float64\n",
      " 17  stroke            205 non-null    float64\n",
      " 18  compressionratio  205 non-null    float64\n",
      " 19  horsepower        205 non-null    int64  \n",
      " 20  peakrpm           205 non-null    int64  \n",
      " 21  citympg           205 non-null    int64  \n",
      " 22  highwaympg        205 non-null    int64  \n",
      " 23  price             205 non-null    float64\n",
      " 24  company_name      205 non-null    int64  \n",
      "dtypes: float64(8), int64(17)\n",
      "memory usage: 40.2 KB\n",
      "None\n",
      "   symboling  fueltype  aspiration  doornumber  carbody  drivewheel  \\\n",
      "0          3         1           0           2        0           2   \n",
      "1          3         1           0           2        0           2   \n",
      "2          1         1           0           2        2           2   \n",
      "3          2         1           0           4        3           1   \n",
      "4          2         1           0           4        3           0   \n",
      "\n",
      "   enginelocation  wheelbase  carlength  carwidth  ...  fuelsystem  boreratio  \\\n",
      "0               0       88.6      168.8      64.1  ...           5       3.47   \n",
      "1               0       88.6      168.8      64.1  ...           5       3.47   \n",
      "2               0       94.5      171.2      65.5  ...           5       2.68   \n",
      "3               0       99.8      176.6      66.2  ...           5       3.19   \n",
      "4               0       99.4      176.6      66.4  ...           5       3.19   \n",
      "\n",
      "   stroke  compressionratio  horsepower  peakrpm  citympg  highwaympg  \\\n",
      "0    2.68               9.0         111     5000       21          27   \n",
      "1    2.68               9.0         111     5000       21          27   \n",
      "2    3.47               9.0         154     5000       19          26   \n",
      "3    3.40              10.0         102     5500       24          30   \n",
      "4    3.40               8.0         115     5500       18          22   \n",
      "\n",
      "     price  company_name  \n",
      "0  13495.0             0  \n",
      "1  16500.0             0  \n",
      "2  16500.0             0  \n",
      "3  13950.0             1  \n",
      "4  17450.0             1  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"processed_car_data.csv\")\n",
    "\n",
    "print(data.info())\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_null(data, column_list, percentage):\n",
    "    \"\"\"\n",
    "    Introduces random null values into specified columns of the data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset to modify.\n",
    "        column_list (list): List of columns to add null values.\n",
    "        percentage (float): Percentage of rows to replace with nulls.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified dataset with null values.\n",
    "    \"\"\"\n",
    "    df_copy = data.copy()  \n",
    "    percentage = percentage / 100\n",
    "    total_rows = df_copy.shape[0]\n",
    "    \n",
    "    for column_name in column_list:\n",
    "        num_nulls = int(total_rows * percentage)\n",
    "        null_indices = np.random.choice(df_copy.index, num_nulls, replace=False)\n",
    "        \n",
    "        if pd.api.types.is_integer_dtype(df_copy[column_name]):\n",
    "            df_copy[column_name] = df_copy[column_name].astype(\"Int64\")\n",
    "        \n",
    "        df_copy.loc[null_indices, column_name] = np.nan\n",
    "        \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_indices(data, columns_list):\n",
    "    \"\"\"Get indices of null values for specified columns.\"\"\"\n",
    "    null_indices_dict = {\n",
    "        column: data.index[data[column].isnull()].tolist()  \n",
    "        for column in columns_list\n",
    "    }\n",
    "    return null_indices_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of discrete and continuous columns\n",
    "discrete_columns = [\"symboling\", \"fueltype\", \"aspiration\", \"doornumber\", \"carbody\", \n",
    "                    \"drivewheel\", \"enginelocation\", \"enginetype\", \"cylindernumber\", \n",
    "                    \"fuelsystem\", \"company_name\"]\n",
    "\n",
    "continuous_columns = [\"horsepower\", \"peakrpm\", \"citympg\", \"highwaympg\", \"enginesize\", \"curbweight\", \n",
    "                      \"wheelbase\", \"carlength\", \"carwidth\", \"carheight\", \"boreratio\", \"stroke\", \n",
    "                      \"compressionratio\", \"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Indices for Discrete Columns:\n",
      "{'symboling': [14, 24, 50, 78, 89, 95, 96, 105, 115, 137, 143, 147, 153, 158, 160, 168, 183, 186, 190, 196], 'fueltype': [8, 12, 17, 29, 30, 32, 35, 47, 51, 61, 68, 71, 109, 130, 141, 159, 162, 185, 193, 198], 'aspiration': [1, 6, 12, 15, 18, 37, 55, 57, 62, 107, 119, 126, 127, 138, 141, 143, 163, 175, 176, 192], 'doornumber': [9, 21, 39, 73, 94, 108, 109, 112, 123, 125, 130, 142, 150, 157, 169, 171, 178, 189, 192, 204], 'carbody': [1, 4, 10, 21, 25, 34, 43, 47, 61, 77, 92, 126, 133, 143, 145, 148, 155, 189, 192, 200], 'drivewheel': [3, 8, 15, 28, 77, 87, 101, 117, 118, 120, 129, 132, 136, 143, 147, 174, 176, 178, 184, 200], 'enginelocation': [14, 15, 24, 36, 37, 40, 43, 44, 45, 90, 95, 122, 124, 138, 140, 152, 160, 186, 190, 196], 'enginetype': [32, 38, 39, 42, 74, 92, 93, 97, 101, 123, 128, 131, 147, 149, 154, 157, 175, 182, 196, 201], 'cylindernumber': [0, 22, 23, 37, 38, 43, 48, 56, 66, 74, 76, 87, 107, 124, 132, 160, 175, 180, 183, 204], 'fuelsystem': [7, 9, 10, 18, 41, 44, 77, 81, 87, 102, 105, 110, 139, 157, 183, 186, 188, 198, 202, 203], 'company_name': [6, 19, 21, 29, 40, 44, 52, 80, 82, 87, 88, 136, 145, 153, 156, 158, 175, 187, 196, 202]}\n",
      "\n",
      "Null Indices for Continuous Columns:\n",
      "{'horsepower': [4, 13, 26, 34, 35, 71, 77, 81, 100, 114, 116, 121, 124, 141, 156, 165, 187, 188, 191, 196], 'peakrpm': [2, 13, 18, 27, 37, 40, 80, 93, 98, 100, 102, 123, 133, 134, 152, 153, 159, 163, 182, 203], 'citympg': [26, 33, 35, 48, 52, 66, 68, 77, 81, 82, 95, 101, 110, 118, 119, 120, 127, 189, 191, 199], 'highwaympg': [0, 20, 25, 28, 31, 44, 47, 56, 60, 65, 97, 141, 148, 152, 155, 161, 162, 168, 169, 171], 'enginesize': [5, 7, 26, 32, 35, 55, 61, 62, 88, 97, 100, 110, 136, 142, 144, 154, 156, 193, 196, 199], 'curbweight': [25, 34, 37, 47, 50, 69, 74, 85, 119, 120, 134, 142, 144, 146, 152, 169, 177, 183, 196, 202], 'wheelbase': [3, 13, 37, 53, 63, 66, 79, 83, 86, 93, 96, 109, 113, 118, 119, 126, 150, 154, 161, 181], 'carlength': [2, 3, 7, 14, 43, 61, 74, 76, 103, 105, 113, 125, 132, 148, 157, 168, 181, 191, 192, 202], 'carwidth': [2, 6, 15, 35, 50, 53, 58, 85, 92, 131, 134, 142, 148, 150, 155, 182, 183, 197, 202, 203], 'carheight': [18, 19, 21, 26, 43, 51, 53, 55, 66, 67, 88, 113, 119, 120, 127, 168, 172, 178, 189, 193], 'boreratio': [12, 14, 15, 18, 39, 52, 55, 87, 89, 104, 107, 124, 126, 132, 165, 177, 182, 184, 197, 199], 'stroke': [16, 21, 25, 29, 39, 61, 66, 81, 97, 111, 118, 122, 127, 162, 170, 174, 177, 195, 199, 203], 'compressionratio': [0, 1, 24, 37, 38, 48, 58, 65, 80, 101, 107, 109, 117, 136, 141, 166, 177, 181, 187, 197], 'price': [6, 11, 13, 16, 33, 50, 75, 78, 81, 110, 112, 116, 141, 147, 154, 160, 163, 173, 177, 192]}\n"
     ]
    }
   ],
   "source": [
    "# Introduce random null values into both discrete and continuous columns\n",
    "data_with_null_values = random_null(data, discrete_columns + continuous_columns, 10)\n",
    "\n",
    "# Get null indices for both discrete and continuous columns\n",
    "discrete_null_indices = get_null_indices(data_with_null_values, discrete_columns)\n",
    "continuous_null_indices = get_null_indices(data_with_null_values, continuous_columns)\n",
    "\n",
    "# Combine both null indices dictionaries\n",
    "null_indices_dict = {**discrete_null_indices, **continuous_null_indices}\n",
    "\n",
    "# Print the null indices for both types\n",
    "print(\"Null Indices for Discrete Columns:\")\n",
    "print(discrete_null_indices)\n",
    "\n",
    "print(\"\\nNull Indices for Continuous Columns:\")\n",
    "print(continuous_null_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_Cleaning_discrete_values(data, null_indices_dict, columns_list, number_of_loops):\n",
    "    \"\"\"\n",
    "    Iteratively fills null values in discrete columns using RandomForestClassifier.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset containing missing values.\n",
    "        null_indices_dict (dict): A dictionary where keys are column names and values are lists of indices with null values.\n",
    "        columns_list (list): List of column names to clean.\n",
    "        number_of_loops (int): Number of iterations to perform the cleaning.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataset with missing values filled.\n",
    "    \"\"\"\n",
    "    for i in range(1, number_of_loops + 1):\n",
    "        for column_name in columns_list:\n",
    "            if column_name not in null_indices_dict:\n",
    "                continue  \n",
    "            \n",
    "            null_indices = null_indices_dict[column_name]\n",
    "            non_null_indices = data.index.difference(null_indices)\n",
    "            \n",
    "            data_without_null_values = data.loc[non_null_indices]\n",
    "            data_with_null_values = data.loc[null_indices]\n",
    "        \n",
    "            x_train = data_without_null_values.drop(columns=[column_name])\n",
    "            y_train = data_without_null_values[column_name]\n",
    "        \n",
    "            model = RandomForestClassifier()\n",
    "            model.fit(x_train, y_train)\n",
    "        \n",
    "            x_test = data_with_null_values.drop(columns=[column_name])\n",
    "        \n",
    "            predicted = model.predict(x_test)\n",
    "        \n",
    "            data.loc[null_indices, column_name] = predicted\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_regression_imputation(data, null_indices_dict, continuous_columns, initial_fill_method_dict, num_rounds):\n",
    "    \"\"\"\n",
    "    Iteratively fills missing values in continuous columns using Linear Regression.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with missing values.\n",
    "        null_indices_dict (dict): Dictionary of columns with null indices.\n",
    "        continuous_columns (list): List of continuous columns to clean.\n",
    "        initial_fill_method_dict (dict): Initial fill methods ('mean', 'median', 'mode').\n",
    "        num_rounds (int): Number of iterative rounds to perform.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with all missing values filled.\n",
    "    \"\"\"\n",
    "    # Step 1: Initial fill using mean, median, or mode\n",
    "    data = fill_continuous_values(data, null_indices_dict, continuous_columns, initial_fill_method_dict) # type: ignore\n",
    "\n",
    "    for _ in range(num_rounds):\n",
    "        for column in continuous_columns:\n",
    "            if column in null_indices_dict:\n",
    "                null_indices = null_indices_dict[column]\n",
    "                if not null_indices:  # Skip if there are no nulls in this column\n",
    "                    continue\n",
    "                \n",
    "                # Prepare training data (other columns are features, target column is the one to predict)\n",
    "                train_data = data.dropna(subset=[column])  # Rows where target column is not null\n",
    "                test_data = data.loc[null_indices]  # Rows where target column is null\n",
    "\n",
    "                x_train = train_data.drop(columns=[column])\n",
    "                y_train = train_data[column]\n",
    "\n",
    "                x_test = test_data.drop(columns=[column])\n",
    "\n",
    "                # Train Linear Regression model\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                # Predict missing values\n",
    "                predicted_values = model.predict(x_test)\n",
    "\n",
    "                # Fill the missing values with the predictions\n",
    "                data.loc[null_indices, column] = predicted_values\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_continuous_values(data, null_indices_dict, columns_list, method_dict):\n",
    "    \"\"\"\n",
    "    Fill missing continuous values in specified columns using the provided method (mean, median, mode).\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing the data with missing values.\n",
    "        null_indices_dict (dict): Dictionary containing indices of null values for each column.\n",
    "        columns_list (list): List of continuous columns to clean.\n",
    "        method_dict (dict): A dictionary where keys are column names and values are the imputation method ('mean', 'median', 'mode').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing continuous values filled.\n",
    "    \"\"\"\n",
    "    for column_name in columns_list:\n",
    "        if column_name in null_indices_dict:\n",
    "            # Determine the method for imputation (mean, median, mode)\n",
    "            method = method_dict.get(column_name, 'mean')  # Default to 'mean' if method is not specified\n",
    "            \n",
    "            # Handle the column type\n",
    "            if method == 'mean':\n",
    "                fill_value = data[column_name].mean()\n",
    "            elif method == 'median':\n",
    "                fill_value = data[column_name].median()\n",
    "            elif method == 'mode':\n",
    "                fill_value = data[column_name].mode()[0]  # Mode can return multiple values, we pick the first\n",
    "            \n",
    "            # If column type is 'Int64', we need to convert to float for mean/median, then round for int columns\n",
    "            if pd.api.types.is_integer_dtype(data[column_name]):\n",
    "                data[column_name] = data[column_name].astype(float)\n",
    "                fill_value = round(fill_value)\n",
    "            \n",
    "            # Fill missing values with the determined fill_value\n",
    "            data[column_name].fillna(fill_value, inplace=True)\n",
    "            \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Assuming 'sample_data' is the DataFrame containing your data with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_dict = {\n",
    "    'wheelbase': 'mean', 'carlength': 'median', 'carwidth': 'mean',\n",
    "    'carheight': 'median', 'curbweight': 'mean', 'enginesize': 'median',\n",
    "    'boreratio': 'mean', 'stroke': 'median', 'compressionratio': 'mean',\n",
    "    'horsepower': 'median', 'peakrpm': 'median', 'citympg': 'mean',\n",
    "    'highwaympg': 'mean', 'price': 'median'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n",
      "C:\\Users\\harme\\AppData\\Local\\Temp\\ipykernel_7828\\664186027.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column_name].fillna(fill_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "sample_discrete = iterative_Cleaning_discrete_values(data_with_null_values, null_indices_dict, discrete_columns, 5)\n",
    "\n",
    "filled_data = iterative_regression_imputation(\n",
    "    data=data_with_null_values,\n",
    "    null_indices_dict=null_indices_dict,\n",
    "    continuous_columns=continuous_columns,\n",
    "    initial_fill_method_dict=method_dict,\n",
    "    num_rounds=5  # Number of iterations\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_filled_columns(original_data, filled_data, null_indices_dict, columns_to_compare):\n",
    "    \"\"\"\n",
    "    Compare specified columns in the original and filled data, showing only filled indices.\n",
    "\n",
    "    Args:\n",
    "        original_data (pd.DataFrame): Original DataFrame before introducing nulls.\n",
    "        filled_data (pd.DataFrame): DataFrame after filling nulls.\n",
    "        null_indices_dict (dict): Dictionary containing indices of null values for each column.\n",
    "        columns_to_compare (list): List of columns to focus on for the comparison.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame showing index, column_name, original_value, and filled_value.\n",
    "    \"\"\"\n",
    "    comparison_results = []\n",
    "\n",
    "    for column in columns_to_compare:\n",
    "        if column in null_indices_dict:  \n",
    "            null_indices = null_indices_dict[column]\n",
    "            for idx in null_indices:\n",
    "                original_value = original_data.at[idx, column]\n",
    "                filled_value = filled_data.at[idx, column]\n",
    "\n",
    "                comparison_results.append({\n",
    "                    'index': idx,\n",
    "                    'column_name': column,\n",
    "                    'original_value': original_value,\n",
    "                    'filled_value': filled_value\n",
    "                })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    return comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index column_name  original_value  filled_value\n",
      "0       3   wheelbase            99.8     98.279055\n",
      "1      13   wheelbase           101.2     98.617288\n",
      "2      37   wheelbase            96.5     97.210278\n",
      "3      53   wheelbase            93.1     95.111840\n",
      "4      63   wheelbase            98.8    101.428123\n",
      "5      66   wheelbase           104.9    102.573710\n",
      "6      79   wheelbase            93.0     92.736057\n",
      "7      83   wheelbase            95.9     95.688036\n",
      "8      86   wheelbase            96.3     96.384905\n",
      "9      93   wheelbase            94.5     95.789372\n",
      "10     96   wheelbase            94.5     95.368171\n",
      "11    109   wheelbase           114.2    107.896242\n",
      "12    113   wheelbase           114.2    108.866978\n",
      "13    118   wheelbase            93.7     92.133871\n",
      "14    119   wheelbase            93.7     93.020245\n",
      "15    126   wheelbase            89.5     89.568175\n",
      "16    150   wheelbase            95.7     94.267780\n",
      "17    154   wheelbase            95.7     97.197952\n",
      "18    161   wheelbase            95.7     96.252550\n",
      "19    181   wheelbase           104.5    102.606880\n"
     ]
    }
   ],
   "source": [
    "# Compare original and filled data for both discrete and continuous columns\n",
    "comparison_df = compare_filled_columns(data, filled_data, null_indices_dict, [\"wheelbase\"])\n",
    "\n",
    "# Display the comparison\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
